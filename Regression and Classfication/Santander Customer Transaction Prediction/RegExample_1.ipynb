{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data=pd.read_csv('santander-customer-transaction-prediction/train.csv')\n",
    "Data=Data.sample(frac=1).reset_index(drop=True)\n",
    "Data=Data.drop(['ID_code'],'columns')\n",
    "Data=Data[Data.target==1].append(Data[Data.target==0].head(20098))\n",
    "Data=Data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_185</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.2158</td>\n",
       "      <td>-7.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4141</td>\n",
       "      <td>1.4879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.8971</td>\n",
       "      <td>1.1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12.3470</td>\n",
       "      <td>-5.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.9837</td>\n",
       "      <td>-9.1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>9.4185</td>\n",
       "      <td>-1.6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10.3376</td>\n",
       "      <td>-4.1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>12.5072</td>\n",
       "      <td>-6.3937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3939</td>\n",
       "      <td>3.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>7.6809</td>\n",
       "      <td>-5.4373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10.7959</td>\n",
       "      <td>-4.8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>10.2496</td>\n",
       "      <td>-0.5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>7.3328</td>\n",
       "      <td>-13.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>10.6693</td>\n",
       "      <td>-1.6748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>12.6615</td>\n",
       "      <td>-12.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>11.3753</td>\n",
       "      <td>-0.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3050</td>\n",
       "      <td>-2.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3066</td>\n",
       "      <td>-4.9327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8649</td>\n",
       "      <td>0.3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>10.6565</td>\n",
       "      <td>5.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0318</td>\n",
       "      <td>-6.3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>8.7734</td>\n",
       "      <td>5.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>9.1101</td>\n",
       "      <td>-3.0253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>8.3378</td>\n",
       "      <td>-4.7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1387</td>\n",
       "      <td>-1.2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>12.7191</td>\n",
       "      <td>6.6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>11.3359</td>\n",
       "      <td>-1.4406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>10.4029</td>\n",
       "      <td>-2.1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>12.6265</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>12.2262</td>\n",
       "      <td>-11.9126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40166</th>\n",
       "      <td>1</td>\n",
       "      <td>15.1932</td>\n",
       "      <td>-3.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40167</th>\n",
       "      <td>0</td>\n",
       "      <td>11.4336</td>\n",
       "      <td>-6.3066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40168</th>\n",
       "      <td>0</td>\n",
       "      <td>9.1171</td>\n",
       "      <td>0.4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40169</th>\n",
       "      <td>0</td>\n",
       "      <td>10.9549</td>\n",
       "      <td>0.7046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40170</th>\n",
       "      <td>0</td>\n",
       "      <td>11.2322</td>\n",
       "      <td>-11.5063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40171</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>-4.5815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40172</th>\n",
       "      <td>1</td>\n",
       "      <td>9.8508</td>\n",
       "      <td>-6.6471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40173</th>\n",
       "      <td>1</td>\n",
       "      <td>10.3317</td>\n",
       "      <td>-9.8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40174</th>\n",
       "      <td>0</td>\n",
       "      <td>12.4914</td>\n",
       "      <td>0.4609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40175</th>\n",
       "      <td>0</td>\n",
       "      <td>9.6283</td>\n",
       "      <td>-3.6949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40176</th>\n",
       "      <td>1</td>\n",
       "      <td>7.4164</td>\n",
       "      <td>-3.6242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40177</th>\n",
       "      <td>0</td>\n",
       "      <td>15.9183</td>\n",
       "      <td>1.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40178</th>\n",
       "      <td>1</td>\n",
       "      <td>6.6813</td>\n",
       "      <td>-16.6613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40179</th>\n",
       "      <td>0</td>\n",
       "      <td>9.9869</td>\n",
       "      <td>0.1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40180</th>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40181</th>\n",
       "      <td>0</td>\n",
       "      <td>12.1955</td>\n",
       "      <td>-8.4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40182</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0924</td>\n",
       "      <td>-4.2783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40183</th>\n",
       "      <td>0</td>\n",
       "      <td>6.8816</td>\n",
       "      <td>-4.8046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40184</th>\n",
       "      <td>1</td>\n",
       "      <td>10.1658</td>\n",
       "      <td>-3.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40185</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0704</td>\n",
       "      <td>-8.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40186</th>\n",
       "      <td>1</td>\n",
       "      <td>12.7946</td>\n",
       "      <td>-10.5613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40187</th>\n",
       "      <td>1</td>\n",
       "      <td>18.2123</td>\n",
       "      <td>-7.1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40188</th>\n",
       "      <td>0</td>\n",
       "      <td>12.8435</td>\n",
       "      <td>-11.0727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40189</th>\n",
       "      <td>0</td>\n",
       "      <td>14.9652</td>\n",
       "      <td>-12.7299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40190</th>\n",
       "      <td>0</td>\n",
       "      <td>7.4551</td>\n",
       "      <td>1.2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40191</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5894</td>\n",
       "      <td>-6.7137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40192</th>\n",
       "      <td>1</td>\n",
       "      <td>7.6858</td>\n",
       "      <td>-7.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40193</th>\n",
       "      <td>1</td>\n",
       "      <td>12.8291</td>\n",
       "      <td>-3.9422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40194</th>\n",
       "      <td>1</td>\n",
       "      <td>12.3436</td>\n",
       "      <td>-4.8426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40195</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5615</td>\n",
       "      <td>-3.2327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target    var_0  var_185\n",
       "0           0  10.2158  -7.5443\n",
       "1           0  14.4141   1.4879\n",
       "2           0  12.8971   1.1912\n",
       "3           1  12.3470  -5.7293\n",
       "4           1  14.9837  -9.1620\n",
       "5           1   9.4185  -1.6982\n",
       "6           0  10.3376  -4.1748\n",
       "7           0  12.5072  -6.3937\n",
       "8           1   8.3939   3.0986\n",
       "9           0   7.6809  -5.4373\n",
       "10          0  10.7959  -4.8799\n",
       "11          0  10.2496  -0.5399\n",
       "12          0   7.3328 -13.0913\n",
       "13          1  10.6693  -1.6748\n",
       "14          1  12.6615 -12.7293\n",
       "15          0  11.3753  -0.6431\n",
       "16          1   6.3050  -2.5316\n",
       "17          1   8.3066  -4.9327\n",
       "18          0   9.8649   0.3094\n",
       "19          0  10.6565   5.0588\n",
       "20          1  16.0318  -6.3470\n",
       "21          0   8.7734   5.0806\n",
       "22          0   9.1101  -3.0253\n",
       "23          0   8.3378  -4.7467\n",
       "24          0  10.1387  -1.2491\n",
       "25          0  12.7191   6.6334\n",
       "26          1  11.3359  -1.4406\n",
       "27          0  10.4029  -2.1781\n",
       "28          1  12.6265   0.5155\n",
       "29          1  12.2262 -11.9126\n",
       "...       ...      ...      ...\n",
       "40166       1  15.1932  -3.0948\n",
       "40167       0  11.4336  -6.3066\n",
       "40168       0   9.1171   0.4976\n",
       "40169       0  10.9549   0.7046\n",
       "40170       0  11.2322 -11.5063\n",
       "40171       0   4.7589  -4.5815\n",
       "40172       1   9.8508  -6.6471\n",
       "40173       1  10.3317  -9.8217\n",
       "40174       0  12.4914   0.4609\n",
       "40175       0   9.6283  -3.6949\n",
       "40176       1   7.4164  -3.6242\n",
       "40177       0  15.9183   1.8716\n",
       "40178       1   6.6813 -16.6613\n",
       "40179       0   9.9869   0.1315\n",
       "40180       1  11.1333   0.0822\n",
       "40181       0  12.1955  -8.4646\n",
       "40182       1  10.0924  -4.2783\n",
       "40183       0   6.8816  -4.8046\n",
       "40184       1  10.1658  -3.2624\n",
       "40185       0   9.0704  -8.1458\n",
       "40186       1  12.7946 -10.5613\n",
       "40187       1  18.2123  -7.1996\n",
       "40188       0  12.8435 -11.0727\n",
       "40189       0  14.9652 -12.7299\n",
       "40190       0   7.4551   1.2521\n",
       "40191       0  11.5894  -6.7137\n",
       "40192       1   7.6858  -7.5033\n",
       "40193       1  12.8291  -3.9422\n",
       "40194       1  12.3436  -4.8426\n",
       "40195       1   6.5615  -3.2327\n",
       "\n",
       "[40196 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=Data.columns.values[2:202]\n",
    "correlation=Data[features].corr().abs().unstack().sort_values(kind='quicksort').reset_index()\n",
    "correlation=correlation[correlation['level_0']!=correlation['level_1']]\n",
    "correlation = correlation[correlation.values[:,2]>0.0099]\n",
    "target=correlation.values[:,1]\n",
    "target=target[::2]\n",
    "target=target.reshape(target.shape[0],1)\n",
    "target=np.unique(target)\n",
    "Data=Data.drop(target,'columns')\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wH9OEpUUkbvNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a80856518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(correlation.values[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['var_81', 'var_166', 'var_71', ..., 'var_81', 'var_164', 'var_43'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = correlation[correlation.values[:,2]>0.0099]\n",
    "target=correlation.values[:,1]\n",
    "target=target[::2]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.5443,  1.4879,  1.1912, ..., -3.9422, -4.8426, -3.2327])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.values[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=target.reshape(1664,1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['var_1', 'var_10', 'var_100', 'var_101', 'var_102', 'var_103',\n",
       "       'var_104', 'var_105', 'var_106', 'var_107', 'var_108', 'var_109',\n",
       "       'var_11', 'var_110', 'var_111', 'var_112', 'var_113', 'var_114',\n",
       "       'var_115', 'var_116', 'var_117', 'var_118', 'var_119', 'var_12',\n",
       "       'var_120', 'var_121', 'var_122', 'var_123', 'var_124', 'var_125',\n",
       "       'var_126', 'var_127', 'var_128', 'var_129', 'var_13', 'var_130',\n",
       "       'var_131', 'var_132', 'var_133', 'var_134', 'var_135', 'var_136',\n",
       "       'var_137', 'var_138', 'var_139', 'var_14', 'var_140', 'var_141',\n",
       "       'var_142', 'var_143', 'var_144', 'var_145', 'var_146', 'var_147',\n",
       "       'var_148', 'var_149', 'var_15', 'var_150', 'var_151', 'var_152',\n",
       "       'var_153', 'var_154', 'var_155', 'var_156', 'var_157', 'var_158',\n",
       "       'var_159', 'var_16', 'var_160', 'var_161', 'var_162', 'var_163',\n",
       "       'var_164', 'var_165', 'var_166', 'var_167', 'var_168', 'var_169',\n",
       "       'var_17', 'var_170', 'var_171', 'var_172', 'var_173', 'var_174',\n",
       "       'var_175', 'var_176', 'var_177', 'var_178', 'var_179', 'var_18',\n",
       "       'var_180', 'var_181', 'var_182', 'var_183', 'var_184', 'var_186',\n",
       "       'var_187', 'var_188', 'var_189', 'var_19', 'var_190', 'var_191',\n",
       "       'var_192', 'var_193', 'var_194', 'var_195', 'var_196', 'var_197',\n",
       "       'var_198', 'var_199', 'var_2', 'var_20', 'var_21', 'var_22',\n",
       "       'var_23', 'var_24', 'var_25', 'var_26', 'var_27', 'var_28',\n",
       "       'var_29', 'var_3', 'var_30', 'var_31', 'var_32', 'var_33', 'var_34',\n",
       "       'var_35', 'var_36', 'var_37', 'var_38', 'var_39', 'var_4', 'var_40',\n",
       "       'var_41', 'var_42', 'var_43', 'var_44', 'var_45', 'var_46',\n",
       "       'var_47', 'var_48', 'var_49', 'var_5', 'var_50', 'var_51', 'var_52',\n",
       "       'var_53', 'var_54', 'var_55', 'var_56', 'var_57', 'var_58',\n",
       "       'var_59', 'var_6', 'var_60', 'var_61', 'var_62', 'var_63', 'var_64',\n",
       "       'var_65', 'var_66', 'var_67', 'var_68', 'var_69', 'var_7', 'var_70',\n",
       "       'var_71', 'var_72', 'var_73', 'var_74', 'var_75', 'var_76',\n",
       "       'var_77', 'var_78', 'var_79', 'var_8', 'var_80', 'var_81', 'var_82',\n",
       "       'var_83', 'var_84', 'var_85', 'var_86', 'var_87', 'var_88',\n",
       "       'var_89', 'var_9', 'var_90', 'var_91', 'var_92', 'var_93', 'var_94',\n",
       "       'var_95', 'var_96', 'var_97', 'var_98', 'var_99'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=np.unique(target)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_185</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.2158</td>\n",
       "      <td>-7.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4141</td>\n",
       "      <td>1.4879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.8971</td>\n",
       "      <td>1.1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12.3470</td>\n",
       "      <td>-5.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.9837</td>\n",
       "      <td>-9.1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>9.4185</td>\n",
       "      <td>-1.6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10.3376</td>\n",
       "      <td>-4.1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>12.5072</td>\n",
       "      <td>-6.3937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3939</td>\n",
       "      <td>3.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>7.6809</td>\n",
       "      <td>-5.4373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10.7959</td>\n",
       "      <td>-4.8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>10.2496</td>\n",
       "      <td>-0.5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>7.3328</td>\n",
       "      <td>-13.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>10.6693</td>\n",
       "      <td>-1.6748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>12.6615</td>\n",
       "      <td>-12.7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>11.3753</td>\n",
       "      <td>-0.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3050</td>\n",
       "      <td>-2.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3066</td>\n",
       "      <td>-4.9327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8649</td>\n",
       "      <td>0.3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>10.6565</td>\n",
       "      <td>5.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0318</td>\n",
       "      <td>-6.3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>8.7734</td>\n",
       "      <td>5.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>9.1101</td>\n",
       "      <td>-3.0253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>8.3378</td>\n",
       "      <td>-4.7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1387</td>\n",
       "      <td>-1.2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>12.7191</td>\n",
       "      <td>6.6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>11.3359</td>\n",
       "      <td>-1.4406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>10.4029</td>\n",
       "      <td>-2.1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>12.6265</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>12.2262</td>\n",
       "      <td>-11.9126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40166</th>\n",
       "      <td>1</td>\n",
       "      <td>15.1932</td>\n",
       "      <td>-3.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40167</th>\n",
       "      <td>0</td>\n",
       "      <td>11.4336</td>\n",
       "      <td>-6.3066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40168</th>\n",
       "      <td>0</td>\n",
       "      <td>9.1171</td>\n",
       "      <td>0.4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40169</th>\n",
       "      <td>0</td>\n",
       "      <td>10.9549</td>\n",
       "      <td>0.7046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40170</th>\n",
       "      <td>0</td>\n",
       "      <td>11.2322</td>\n",
       "      <td>-11.5063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40171</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7589</td>\n",
       "      <td>-4.5815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40172</th>\n",
       "      <td>1</td>\n",
       "      <td>9.8508</td>\n",
       "      <td>-6.6471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40173</th>\n",
       "      <td>1</td>\n",
       "      <td>10.3317</td>\n",
       "      <td>-9.8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40174</th>\n",
       "      <td>0</td>\n",
       "      <td>12.4914</td>\n",
       "      <td>0.4609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40175</th>\n",
       "      <td>0</td>\n",
       "      <td>9.6283</td>\n",
       "      <td>-3.6949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40176</th>\n",
       "      <td>1</td>\n",
       "      <td>7.4164</td>\n",
       "      <td>-3.6242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40177</th>\n",
       "      <td>0</td>\n",
       "      <td>15.9183</td>\n",
       "      <td>1.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40178</th>\n",
       "      <td>1</td>\n",
       "      <td>6.6813</td>\n",
       "      <td>-16.6613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40179</th>\n",
       "      <td>0</td>\n",
       "      <td>9.9869</td>\n",
       "      <td>0.1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40180</th>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40181</th>\n",
       "      <td>0</td>\n",
       "      <td>12.1955</td>\n",
       "      <td>-8.4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40182</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0924</td>\n",
       "      <td>-4.2783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40183</th>\n",
       "      <td>0</td>\n",
       "      <td>6.8816</td>\n",
       "      <td>-4.8046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40184</th>\n",
       "      <td>1</td>\n",
       "      <td>10.1658</td>\n",
       "      <td>-3.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40185</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0704</td>\n",
       "      <td>-8.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40186</th>\n",
       "      <td>1</td>\n",
       "      <td>12.7946</td>\n",
       "      <td>-10.5613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40187</th>\n",
       "      <td>1</td>\n",
       "      <td>18.2123</td>\n",
       "      <td>-7.1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40188</th>\n",
       "      <td>0</td>\n",
       "      <td>12.8435</td>\n",
       "      <td>-11.0727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40189</th>\n",
       "      <td>0</td>\n",
       "      <td>14.9652</td>\n",
       "      <td>-12.7299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40190</th>\n",
       "      <td>0</td>\n",
       "      <td>7.4551</td>\n",
       "      <td>1.2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40191</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5894</td>\n",
       "      <td>-6.7137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40192</th>\n",
       "      <td>1</td>\n",
       "      <td>7.6858</td>\n",
       "      <td>-7.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40193</th>\n",
       "      <td>1</td>\n",
       "      <td>12.8291</td>\n",
       "      <td>-3.9422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40194</th>\n",
       "      <td>1</td>\n",
       "      <td>12.3436</td>\n",
       "      <td>-4.8426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40195</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5615</td>\n",
       "      <td>-3.2327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target    var_0  var_185\n",
       "0           0  10.2158  -7.5443\n",
       "1           0  14.4141   1.4879\n",
       "2           0  12.8971   1.1912\n",
       "3           1  12.3470  -5.7293\n",
       "4           1  14.9837  -9.1620\n",
       "5           1   9.4185  -1.6982\n",
       "6           0  10.3376  -4.1748\n",
       "7           0  12.5072  -6.3937\n",
       "8           1   8.3939   3.0986\n",
       "9           0   7.6809  -5.4373\n",
       "10          0  10.7959  -4.8799\n",
       "11          0  10.2496  -0.5399\n",
       "12          0   7.3328 -13.0913\n",
       "13          1  10.6693  -1.6748\n",
       "14          1  12.6615 -12.7293\n",
       "15          0  11.3753  -0.6431\n",
       "16          1   6.3050  -2.5316\n",
       "17          1   8.3066  -4.9327\n",
       "18          0   9.8649   0.3094\n",
       "19          0  10.6565   5.0588\n",
       "20          1  16.0318  -6.3470\n",
       "21          0   8.7734   5.0806\n",
       "22          0   9.1101  -3.0253\n",
       "23          0   8.3378  -4.7467\n",
       "24          0  10.1387  -1.2491\n",
       "25          0  12.7191   6.6334\n",
       "26          1  11.3359  -1.4406\n",
       "27          0  10.4029  -2.1781\n",
       "28          1  12.6265   0.5155\n",
       "29          1  12.2262 -11.9126\n",
       "...       ...      ...      ...\n",
       "40166       1  15.1932  -3.0948\n",
       "40167       0  11.4336  -6.3066\n",
       "40168       0   9.1171   0.4976\n",
       "40169       0  10.9549   0.7046\n",
       "40170       0  11.2322 -11.5063\n",
       "40171       0   4.7589  -4.5815\n",
       "40172       1   9.8508  -6.6471\n",
       "40173       1  10.3317  -9.8217\n",
       "40174       0  12.4914   0.4609\n",
       "40175       0   9.6283  -3.6949\n",
       "40176       1   7.4164  -3.6242\n",
       "40177       0  15.9183   1.8716\n",
       "40178       1   6.6813 -16.6613\n",
       "40179       0   9.9869   0.1315\n",
       "40180       1  11.1333   0.0822\n",
       "40181       0  12.1955  -8.4646\n",
       "40182       1  10.0924  -4.2783\n",
       "40183       0   6.8816  -4.8046\n",
       "40184       1  10.1658  -3.2624\n",
       "40185       0   9.0704  -8.1458\n",
       "40186       1  12.7946 -10.5613\n",
       "40187       1  18.2123  -7.1996\n",
       "40188       0  12.8435 -11.0727\n",
       "40189       0  14.9652 -12.7299\n",
       "40190       0   7.4551   1.2521\n",
       "40191       0  11.5894  -6.7137\n",
       "40192       1   7.6858  -7.5033\n",
       "40193       1  12.8291  -3.9422\n",
       "40194       1  12.3436  -4.8426\n",
       "40195       1   6.5615  -3.2327\n",
       "\n",
       "[40196 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=Data.drop(target,'columns')\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,X0,y,Y0=train_test_split(X,Y,test_size=0.25,random_state=42)\n",
    "X1,X2,Y1,Y2=train_test_split(x,y,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rampr\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model1=XGBClassifier()\n",
    "model2=SGDClassifier(alpha=0.00701,random_state=64,n_iter=4,n_jobs=-1)\n",
    "model3=AdaBoostClassifier(LogisticRegression(C=9.1,max_iter=1000,verbose=0,n_jobs=-1,solver='sag'))\n",
    "model4=SVC(coef0=0.9,degree=6,random_state=0,kernel='poly')\n",
    "model5=KNeighborsClassifier(leaf_size=3,n_neighbors=4,p=2,n_jobs=-1)\n",
    "model6=RandomForestClassifier(n_estimators=66,max_depth=2,min_samples_leaf=0.1,min_samples_split=0.1,random_state=0,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = Sequential()\n",
    "final.add(Dense(units = 1024, input_dim=X.shape[1], activation = 'relu'))     #Hidden Layer 1 with 512 nods and relu actification function\n",
    "final.add(Dense(units = 512, activation = 'sigmoid'))     #Hidden Layer 2 with 256 nods and relu actification function\n",
    "final.add(Dense(units = 256, activation = 'relu'))     #Hidden Layer 2 with 256 nods and relu actification function\n",
    "final.add(Dense(units = 128, activation = 'sigmoid'))     #Hidden Layer 3 with 5128 nods and relu actification function\n",
    "final.add(Dense(units = 64, activation = 'sigmoid'))\n",
    "final.add(Dense(units = 1, activation = 'sigmoid'))   #Output Layer 4 with 62 nods and sigmoid actification function\n",
    "\n",
    "final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  #Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.fit(X0,Y0)\n",
    "model2.fit(X0,Y0)\n",
    "model3.fit(X0,Y0)\n",
    "model4.fit(X0,Y0)\n",
    "model5.fit(X0,Y0)\n",
    "model6.fit(X0,Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xmp=model1.predict(X1)\n",
    "Xmp=np.append(Xmp,model2.predict(Xmp).reshape(Xmp.shape[0],1), axis=1)\n",
    "Xmp=np.append(Xmp,model3.predict(Xmp).reshape(Xmp.shape[0],1), axis=1)\n",
    "Xmp=np.append(Xmp,model4.predict(Xmp).reshape(Xmp.shape[0],1), axis=1)\n",
    "Xmp=np.append(Xmp,model5.predict(Xmp).reshape(Xmp.shape[0],1), axis=1)\n",
    "Xmp=np.append(Xmp,model6.predict(Xmp).reshape(Xmp.shape[0],1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "      <td>40196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.900694</td>\n",
       "      <td>-1.372290</td>\n",
       "      <td>10.926077</td>\n",
       "      <td>6.830321</td>\n",
       "      <td>11.100943</td>\n",
       "      <td>-4.723319</td>\n",
       "      <td>5.484211</td>\n",
       "      <td>16.512380</td>\n",
       "      <td>0.386093</td>\n",
       "      <td>...</td>\n",
       "      <td>3.574776</td>\n",
       "      <td>7.615577</td>\n",
       "      <td>1.840381</td>\n",
       "      <td>3.241596</td>\n",
       "      <td>17.898202</td>\n",
       "      <td>-0.085334</td>\n",
       "      <td>2.490530</td>\n",
       "      <td>8.869306</td>\n",
       "      <td>15.664521</td>\n",
       "      <td>-3.018717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>3.155630</td>\n",
       "      <td>4.125188</td>\n",
       "      <td>2.739550</td>\n",
       "      <td>2.059930</td>\n",
       "      <td>1.628233</td>\n",
       "      <td>8.011988</td>\n",
       "      <td>0.892864</td>\n",
       "      <td>3.406666</td>\n",
       "      <td>3.325999</td>\n",
       "      <td>...</td>\n",
       "      <td>4.695407</td>\n",
       "      <td>3.118686</td>\n",
       "      <td>1.485509</td>\n",
       "      <td>4.025340</td>\n",
       "      <td>3.170687</td>\n",
       "      <td>1.456655</td>\n",
       "      <td>5.504951</td>\n",
       "      <td>0.939056</td>\n",
       "      <td>3.126172</td>\n",
       "      <td>10.431851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-14.091000</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>5.834300</td>\n",
       "      <td>-28.246100</td>\n",
       "      <td>2.496000</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-9.991100</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.343000</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>9.827700</td>\n",
       "      <td>-5.018500</td>\n",
       "      <td>-14.020400</td>\n",
       "      <td>6.119000</td>\n",
       "      <td>6.558700</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.566400</td>\n",
       "      <td>-4.541200</td>\n",
       "      <td>8.841050</td>\n",
       "      <td>5.284950</td>\n",
       "      <td>9.897475</td>\n",
       "      <td>-10.944150</td>\n",
       "      <td>4.818075</td>\n",
       "      <td>13.897300</td>\n",
       "      <td>-2.190525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149625</td>\n",
       "      <td>5.259675</td>\n",
       "      <td>0.784100</td>\n",
       "      <td>0.486325</td>\n",
       "      <td>15.534925</td>\n",
       "      <td>-1.136950</td>\n",
       "      <td>-1.767850</td>\n",
       "      <td>8.214275</td>\n",
       "      <td>13.572875</td>\n",
       "      <td>-10.818875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.741250</td>\n",
       "      <td>-1.344400</td>\n",
       "      <td>10.822300</td>\n",
       "      <td>6.867750</td>\n",
       "      <td>11.128950</td>\n",
       "      <td>-4.471800</td>\n",
       "      <td>5.473200</td>\n",
       "      <td>16.415750</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>...</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>7.533100</td>\n",
       "      <td>1.789600</td>\n",
       "      <td>3.284650</td>\n",
       "      <td>17.849350</td>\n",
       "      <td>-0.118250</td>\n",
       "      <td>2.645400</td>\n",
       "      <td>8.854500</td>\n",
       "      <td>15.711450</td>\n",
       "      <td>-2.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.039025</td>\n",
       "      <td>1.628600</td>\n",
       "      <td>12.749625</td>\n",
       "      <td>8.358925</td>\n",
       "      <td>12.287125</td>\n",
       "      <td>1.283050</td>\n",
       "      <td>6.092450</td>\n",
       "      <td>19.051425</td>\n",
       "      <td>3.017125</td>\n",
       "      <td>...</td>\n",
       "      <td>6.841650</td>\n",
       "      <td>9.713375</td>\n",
       "      <td>2.870525</td>\n",
       "      <td>6.128550</td>\n",
       "      <td>20.322475</td>\n",
       "      <td>0.896925</td>\n",
       "      <td>6.760350</td>\n",
       "      <td>9.572325</td>\n",
       "      <td>17.948225</td>\n",
       "      <td>5.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>9.304300</td>\n",
       "      <td>18.410100</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>15.991400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.285200</td>\n",
       "      <td>27.039800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>16.746100</td>\n",
       "      <td>16.520500</td>\n",
       "      <td>7.647600</td>\n",
       "      <td>17.239300</td>\n",
       "      <td>27.295300</td>\n",
       "      <td>4.088100</td>\n",
       "      <td>17.332600</td>\n",
       "      <td>11.827700</td>\n",
       "      <td>25.857100</td>\n",
       "      <td>27.534000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target         var_0         var_1         var_2         var_3  \\\n",
       "count  40196.000000  40196.000000  40196.000000  40196.000000  40196.000000   \n",
       "mean       0.500000     10.900694     -1.372290     10.926077      6.830321   \n",
       "std        0.500006      3.155630      4.125188      2.739550      2.059930   \n",
       "min        0.000000      0.408400    -14.091000      2.117100      0.374000   \n",
       "25%        0.000000      8.566400     -4.541200      8.841050      5.284950   \n",
       "50%        0.500000     10.741250     -1.344400     10.822300      6.867750   \n",
       "75%        1.000000     13.039025      1.628600     12.749625      8.358925   \n",
       "max        1.000000     20.315000      9.304300     18.410100     13.188300   \n",
       "\n",
       "              var_4         var_5         var_6         var_7         var_8  \\\n",
       "count  40196.000000  40196.000000  40196.000000  40196.000000  40196.000000   \n",
       "mean      11.100943     -4.723319      5.484211     16.512380      0.386093   \n",
       "std        1.628233      8.011988      0.892864      3.406666      3.325999   \n",
       "min        5.834300    -28.246100      2.496000      5.349700     -9.991100   \n",
       "25%        9.897475    -10.944150      4.818075     13.897300     -2.190525   \n",
       "50%       11.128950     -4.471800      5.473200     16.415750      0.503400   \n",
       "75%       12.287125      1.283050      6.092450     19.051425      3.017125   \n",
       "max       15.991400     17.251600      8.285200     27.039800     10.151300   \n",
       "\n",
       "           ...            var_190       var_191       var_192       var_193  \\\n",
       "count      ...       40196.000000  40196.000000  40196.000000  40196.000000   \n",
       "mean       ...           3.574776      7.615577      1.840381      3.241596   \n",
       "std        ...           4.695407      3.118686      1.485509      4.025340   \n",
       "min        ...         -14.093300     -2.343000     -3.814500    -11.783400   \n",
       "25%        ...           0.149625      5.259675      0.784100      0.486325   \n",
       "50%        ...           3.550000      7.533100      1.789600      3.284650   \n",
       "75%        ...           6.841650      9.713375      2.870525      6.128550   \n",
       "max        ...          16.746100     16.520500      7.647600     17.239300   \n",
       "\n",
       "            var_194       var_195       var_196       var_197       var_198  \\\n",
       "count  40196.000000  40196.000000  40196.000000  40196.000000  40196.000000   \n",
       "mean      17.898202     -0.085334      2.490530      8.869306     15.664521   \n",
       "std        3.170687      1.456655      5.504951      0.939056      3.126172   \n",
       "min        9.827700     -5.018500    -14.020400      6.119000      6.558700   \n",
       "25%       15.534925     -1.136950     -1.767850      8.214275     13.572875   \n",
       "50%       17.849350     -0.118250      2.645400      8.854500     15.711450   \n",
       "75%       20.322475      0.896925      6.760350      9.572325     17.948225   \n",
       "max       27.295300      4.088100     17.332600     11.827700     25.857100   \n",
       "\n",
       "            var_199  \n",
       "count  40196.000000  \n",
       "mean      -3.018717  \n",
       "std       10.431851  \n",
       "min      -38.852800  \n",
       "25%      -10.818875  \n",
       "50%       -2.509300  \n",
       "75%        5.148700  \n",
       "max       27.534000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZd0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x237bc65a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x.values[7,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=preprocessing.MinMaxScaler().fit_transform(Data.values[:,1:])\n",
    "X, X1, y, y1 = model_selection.train_test_split(Data.values[:,1:], Data.values[:,0], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rampr\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model=XGBClassifier()\n",
    "model1=linear_model.SGDClassifier(alpha=0.00701,random_state=64,n_iter=4,n_jobs=-1)\n",
    "model2=neighbors.KNeighborsClassifier(leaf_size=3,n_neighbors=4,p=2,n_jobs=-1)\n",
    "model3=ensemble.RandomForestClassifier(n_estimators=66,max_depth=2,min_samples_leaf=0.1,min_samples_split=0.1,random_state=0,n_jobs=-1)\n",
    "\n",
    "final1=neural_network.MLPClassifier(hidden_layer_sizes=(100,50,25),max_iter=450,random_state=95,beta_1=0.90000000000000002,beta_2=0.70000000000000007)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.7000000000000001, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=450, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=95, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)\n",
    "model1.fit(X,y)\n",
    "model2.fit(X,y)\n",
    "model3.fit(X,y)\n",
    "final1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre1=model.predict(X1)\n",
    "pre2=model1.predict(X1)\n",
    "pre3=model2.predict(X1)\n",
    "pre4=model3.predict(X1)\n",
    "pre5=final1.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74540002855213439"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1, pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73926326066007086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1, pre2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53482490902770319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1, pre3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68353957972272428"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1, pre4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74933482004074614"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1, pre5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final1.fit(Xhidden,y2)\n",
    "final2.fit(Xhidden,y2)\n",
    "\n",
    "Xhidden1=model.predict(X3).reshape(X3.shape[0],1)\n",
    "Xhidden1=np.append(Xhidden1,model1.predict(X3).reshape(Xhidden1.shape[0],1), axis=1)\n",
    "Xhidden1=np.append(Xhidden1,model2.predict(X3).reshape(Xhidden1.shape[0],1), axis=1)\n",
    "Xhidden1=np.append(Xhidden1,model3.predict(X3).reshape(Xhidden1.shape[0],1), axis=1)\n",
    "\n",
    "Xhidden2=final1.predict(Xhidden1).reshape(Xhidden1.shape[0],1)\n",
    "Xhidden2=np.append(Xhidden2,final2.predict(Xhidden1).reshape(Xhidden2.shape[0],1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=XGBClassifier()\n",
    "final.fit(Xhidden2,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74607901528687715"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhidden3=model.predict(X4).reshape(X4.shape[0],1)\n",
    "Xhidden3=np.append(Xhidden3,model1.predict(X4).reshape(Xhidden3.shape[0],1), axis=1)\n",
    "Xhidden3=np.append(Xhidden3,model2.predict(X4).reshape(Xhidden3.shape[0],1), axis=1)\n",
    "Xhidden3=np.append(Xhidden3,model3.predict(X4).reshape(Xhidden3.shape[0],1), axis=1)\n",
    "\n",
    "Xhidden4=final1.predict(Xhidden3).reshape(Xhidden3.shape[0],1)\n",
    "Xhidden4=np.append(Xhidden4,final2.predict(Xhidden3).reshape(Xhidden4.shape[0],1), axis=1)\n",
    "\n",
    "final.score(Xhidden4,y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10074,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data=pd.read_csv('santander-customer-transaction-prediction/test.csv')\n",
    "Data=Data.drop(['ID_code'],'columns')\n",
    "\n",
    "X=preprocessing.MinMaxScaler().fit_transform(Data.values)\n",
    "\n",
    "Xhidden=model.predict(X).reshape(X.shape[0],1)\n",
    "Xhidden=np.append(Xhidden,model1.predict(X).reshape(Xhidden.shape[0],1), axis=1)\n",
    "Xhidden=np.append(Xhidden,model2.predict(X).reshape(Xhidden.shape[0],1), axis=1)\n",
    "Xhidden=np.append(Xhidden,model3.predict(X).reshape(Xhidden.shape[0],1), axis=1)\n",
    "\n",
    "Xhidden1=final1.predict(Xhidden).reshape(Xhidden.shape[0],1)\n",
    "Xhidden1=np.append(Xhidden1,final2.predict(Xhidden).reshape(Xhidden1.shape[0],1), axis=1)\n",
    "\n",
    "y=final.predict(Xhidden2)\n",
    "y=y.astype(int)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 10074 does not match index length 200000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b010ff198cb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'santander-customer-transaction-prediction/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'ID_code'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID_code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Santander_Customer_Transaction_Prediction.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    273\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    274\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   5494\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5496\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5497\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5498\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   5552\u001b[0m                     msg = ('array length %d does not match index length %d' %\n\u001b[0;32m   5553\u001b[0m                            (lengths[0], len(index)))\n\u001b[1;32m-> 5554\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5555\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5556\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array length 10074 does not match index length 200000"
     ]
    }
   ],
   "source": [
    "Data=pd.read_csv('santander-customer-transaction-prediction/test.csv')\n",
    "submission = pd.DataFrame({'ID_code':Data['ID_code'],'target':y})\n",
    "filename = 'Santander_Customer_Transaction_Prediction.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/ed/88e6bfb6ed363725480847b63d571283afb35031bc76d04d40d2c1960e78/h5py-2.9.0-cp35-cp35m-win_amd64.whl\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\rampr\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages (from keras) (0.19.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\rampr\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages (from keras) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\rampr\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages (from keras) (1.13.1)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/74/82496ef0a3e0ec47f4c40ea19a9d7bf0371034d1e4dddda3fbc6f8898aed/PyYAML-5.1-cp35-cp35m-win_amd64.whl (208kB)\n",
      "Installing collected packages: h5py, keras-applications, keras-preprocessing, pyyaml, keras\n",
      "Successfully installed h5py-2.9.0 keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9 pyyaml-5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twosigmanews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement twosigmanews (from versions: )\n",
      "No matching distribution found for twosigmanews\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install twosigmanews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data=pd.read_csv('Classifier/Santander_Customer_Transaction_Prediction_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26f0713d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Data.values[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
